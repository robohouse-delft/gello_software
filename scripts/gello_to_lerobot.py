from typing import Dict
import pickle
import shutil
from pathlib import Path

from PIL import Image as PILImage
import numpy as np
import tqdm

from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata

# ---------- CONFIG ----------
GELLO_FEATURES = {
    "observation.state": {"dtype": "float32", "shape": (7,), "names": ["joint_0", "joint_1", "joint_2", "joint_3", "joint_4", "joint_5", "gripper"]},
    # "observation.state": {"dtype": "float32", "shape": (7,), "names": ["joint_positions"]},
    # "observation.joint_vel": {"dtype": "float32", "shape": (7,), "names": ["joint_velocities"]},
    # "observation.state": {"dtype": "float32", "shape": (8,), "names": ["x", "y", "z", "q_x", "q_y", "q_z", "q_w", "gripper"]},
    "observation.images.wrist.rgb": {"dtype": "video", "shape": (480, 640, 3), "names": ["height", "width", "channel"]},
    # "observation.images.wrist.depth": {"dtype": "video", "shape": (256, 256, 3), "names": ["height", "width", "channel"]},
    "observation.images.base.rgb": {"dtype": "video", "shape": (480, 640, 3), "names": ["height", "width", "channel"]},
    # "observation.images.base.depth": {"dtype": "video", "shape": (256, 256, 3), "names": ["height", "width", "channel"]},
    # "action": {"dtype": "float32", "shape": (7,), "names": ["joint_commands"]},
    "action": {"dtype": "float32", "shape": (7,), "names": ["joint_0", "joint_1", "joint_2", "joint_3", "joint_4", "joint_5", "gripper"]},
    # "action": {"dtype": "float32", "shape": (8,), "names": ["x", "y", "z", "q_x", "q_y", "q_z", "q_w", "gripper"]},
}

def depth_to_rgb(depth_img):
    """Convert single-channel depth image to 3-channel grayscale RGB."""
    if depth_img.ndim == 3 and depth_img.shape[-1] == 1:  # (H, W, 1)
        return np.repeat(depth_img, 3, axis=-1)
    elif depth_img.ndim == 3 and depth_img.shape[0] == 1:  # (1, H, W)
        return np.repeat(depth_img, 3, axis=0)
    else:
        raise ValueError(f"Unexpected depth shape: {depth_img.shape}")

def to_channels_last(img):
    if hasattr(img, "permute"):  # torch.Tensor
        return img.permute(1, 2, 0)
    elif isinstance(img, np.ndarray):
        return np.transpose(img, (1, 2, 0))
    else:
        raise TypeError(f"Unsupported image type: {type(img)}")

def to_lerobot_frame(step_data: Dict) -> Dict:
    # Remap keys
    frame = {}
    frame["observation.state"] = step_data["joint_positions"].astype(np.float32)
    # frame["observation.joint_vel"] = step_data["joint_velocities"].astype(np.float32)
    # frame["observation.state"] = step_data["ee_pos_quat"].astype(np.float32) + step_data["joint_positions"].astype(np.float32)[-1]
    frame["action"] = step_data["control"].astype(np.float32)

    # Handle images
    for key in list(step_data.keys()):
        # if "rgb" in key or "depth" in key:
        if "rgb" in key:
            cam_name, img_type = key.split("_")[0], key.split("_")[1]
            new_key = f"observation.images.{cam_name}.{img_type}"
            img = step_data[key].astype("uint8")
            if "depth" in key:
                img = depth_to_rgb(img)
            # Resize image. 
            # img = np.array(PILImage.fromarray(img).resize((256, 256), PILImage.Resampling.BICUBIC))
            frame[new_key] = np.array(img)
    return frame


def process_episode(episode_path, dataset, fps, task_name):
    """Load one episode and save it directly to LeRobotDataset."""
    step_paths = sorted(episode_path.glob("*.pkl"))

    assert len(step_paths) > 0, "No pickle files found in GELLO dataset"

    for _, step_path in enumerate(step_paths):
        with open(step_path, "rb") as f:
            step_data = pickle.load(f)

        frame = to_lerobot_frame(step_data)
        dataset.add_frame(frame, task=task_name)

    dataset.save_episode()
    # del step_data, frame
    # torch.cuda.empty_cache()

def convert_to_lerobot(raw_dir, repo_name, task_name, fps=30):
    dataset_path = Path.home() / ".cache/huggingface/lerobot" / repo_name
    if dataset_path.exists():
        print(f"Deleting existing dataset folder: {dataset_path}")
        shutil.rmtree(dataset_path)

    dataset = LeRobotDataset.create(
        repo_id=repo_name,
        fps=fps,
        features=GELLO_FEATURES,
        image_writer_threads=10,
        image_writer_processes=5,
    )

    episode_paths = sorted([x for x in Path(raw_dir).glob("*") if x.is_dir()])

    assert len(episode_paths) > 0, "No episode directories found in GELLO dataset"

    for ep_path in tqdm.tqdm(episode_paths, desc="Processing episodes"):
        process_episode(ep_path, dataset, fps, task_name)

    print("Conversion complete!")
    ds_meta = LeRobotDatasetMetadata(repo_name)
    print(ds_meta)

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        prog='gello_to_lerobot',
        description='Converts the pickle files that were generated by the GELLO tele-operation process to an equilavent LeRobot dataset.'
    )
    parser.add_argument("-i", "--input", required=True, help="The directory that holds all the pickle files. This should be the root directory that contains all episodes (each episode is contained in its own directory).")
    parser.add_argument("-n", "--name", required=True, help="The name of the LeRobot output dataset")
    parser.add_argument("-t", '--task', required=True, help="The task that describes what was done over all episodes (assumes a single task).")
    parser.add_argument("-f", "--fps", default=30, help="The data recording rate in frames per second. This is the rate at which observations were recorded, i.e. in this case the rate of the camera capture")
    
    args = parser.parse_args()

    convert_to_lerobot(args.input, args.name, args.task, int(args.fps))
